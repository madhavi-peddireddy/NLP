{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"NLTK is a great tool for learning and for tasks that require flexibility and a wide range of NLP functions. It's more suited for academic and research purposes where detailed customization and a wide array of tools are necessary. spaCy is designed for performance and ease of use! making it ideal for production environments where speed and accuracy are critical. It's highly efficient and comes with excellent pre-trained models, making it a strong choice for industrial applications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK is a great tool for learning and for tasks that require flexibility and a wide range of NLP functions. It's more suited for academic and research purposes where detailed customization and a wide array of tools are necessary. spaCy is designed for performance and ease of use! making it ideal for production environments where speed and accuracy are critical. It's highly efficient and comes with excellent pre-trained models, making it a strong choice for industrial applications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK is a great tool for learning and for tasks that require flexibility and a wide range of NLP functions.',\n",
       " \"It's more suited for academic and research purposes where detailed customization and a wide array of tools are necessary.\",\n",
       " 'spaCy is designed for performance and ease of use!',\n",
       " 'making it ideal for production environments where speed and accuracy are critical.',\n",
       " \"It's highly efficient and comes with excellent pre-trained models, making it a strong choice for industrial applications.\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "#Paragraph-->Sentence\n",
    "from nltk.tokenize import sent_tokenize\n",
    "documents=sent_tokenize(corpus)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: When we do tokenization from paragraph into sentence it looks for full stop or exclamation.\n",
    "NLTK is a string processing library. It takes strings as input and returns strings or lists of strings as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK is a great tool for learning and for tasks that require flexibility and a wide range of NLP functions.\n",
      "It's more suited for academic and research purposes where detailed customization and a wide array of tools are necessary.\n",
      "spaCy is designed for performance and ease of use!\n",
      "making it ideal for production environments where speed and accuracy are critical.\n",
      "It's highly efficient and comes with excellent pre-trained models, making it a strong choice for industrial applications.\n"
     ]
    }
   ],
   "source": [
    "#Print sentences\n",
    "for i in documents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tool',\n",
       " 'for',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'for',\n",
       " 'tasks',\n",
       " 'that',\n",
       " 'require',\n",
       " 'flexibility',\n",
       " 'and',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'functions',\n",
       " '.',\n",
       " 'It',\n",
       " \"'s\",\n",
       " 'more',\n",
       " 'suited',\n",
       " 'for',\n",
       " 'academic',\n",
       " 'and',\n",
       " 'research',\n",
       " 'purposes',\n",
       " 'where',\n",
       " 'detailed',\n",
       " 'customization',\n",
       " 'and',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'array',\n",
       " 'of',\n",
       " 'tools',\n",
       " 'are',\n",
       " 'necessary',\n",
       " '.',\n",
       " 'spaCy',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'for',\n",
       " 'performance',\n",
       " 'and',\n",
       " 'ease',\n",
       " 'of',\n",
       " 'use',\n",
       " '!',\n",
       " 'making',\n",
       " 'it',\n",
       " 'ideal',\n",
       " 'for',\n",
       " 'production',\n",
       " 'environments',\n",
       " 'where',\n",
       " 'speed',\n",
       " 'and',\n",
       " 'accuracy',\n",
       " 'are',\n",
       " 'critical',\n",
       " '.',\n",
       " 'It',\n",
       " \"'s\",\n",
       " 'highly',\n",
       " 'efficient',\n",
       " 'and',\n",
       " 'comes',\n",
       " 'with',\n",
       " 'excellent',\n",
       " 'pre-trained',\n",
       " 'models',\n",
       " ',',\n",
       " 'making',\n",
       " 'it',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'choice',\n",
       " 'for',\n",
       " 'industrial',\n",
       " 'applications',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Tokenization\n",
    "# Paragraph-->words\n",
    "# Sentence-->words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation : It's -- It', \"'s\",  if there is apostrophe it converting into two words It's converted to 'It' and \"'s\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLTK', 'is', 'a', 'great', 'tool', 'for', 'learning', 'and', 'for', 'tasks', 'that', 'require', 'flexibility', 'and', 'a', 'wide', 'range', 'of', 'NLP', 'functions', '.']\n",
      "['It', \"'s\", 'more', 'suited', 'for', 'academic', 'and', 'research', 'purposes', 'where', 'detailed', 'customization', 'and', 'a', 'wide', 'array', 'of', 'tools', 'are', 'necessary', '.']\n",
      "['spaCy', 'is', 'designed', 'for', 'performance', 'and', 'ease', 'of', 'use', '!']\n",
      "['making', 'it', 'ideal', 'for', 'production', 'environments', 'where', 'speed', 'and', 'accuracy', 'are', 'critical', '.']\n",
      "['It', \"'s\", 'highly', 'efficient', 'and', 'comes', 'with', 'excellent', 'pre-trained', 'models', ',', 'making', 'it', 'a', 'strong', 'choice', 'for', 'industrial', 'applications', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tool',\n",
       " 'for',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'for',\n",
       " 'tasks',\n",
       " 'that',\n",
       " 'require',\n",
       " 'flexibility',\n",
       " 'and',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'functions',\n",
       " '.',\n",
       " 'It',\n",
       " \"'\",\n",
       " 's',\n",
       " 'more',\n",
       " 'suited',\n",
       " 'for',\n",
       " 'academic',\n",
       " 'and',\n",
       " 'research',\n",
       " 'purposes',\n",
       " 'where',\n",
       " 'detailed',\n",
       " 'customization',\n",
       " 'and',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'array',\n",
       " 'of',\n",
       " 'tools',\n",
       " 'are',\n",
       " 'necessary',\n",
       " '.',\n",
       " 'spaCy',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'for',\n",
       " 'performance',\n",
       " 'and',\n",
       " 'ease',\n",
       " 'of',\n",
       " 'use',\n",
       " '!',\n",
       " 'making',\n",
       " 'it',\n",
       " 'ideal',\n",
       " 'for',\n",
       " 'production',\n",
       " 'environments',\n",
       " 'where',\n",
       " 'speed',\n",
       " 'and',\n",
       " 'accuracy',\n",
       " 'are',\n",
       " 'critical',\n",
       " '.',\n",
       " 'It',\n",
       " \"'\",\n",
       " 's',\n",
       " 'highly',\n",
       " 'efficient',\n",
       " 'and',\n",
       " 'comes',\n",
       " 'with',\n",
       " 'excellent',\n",
       " 'pre',\n",
       " '-',\n",
       " 'trained',\n",
       " 'models',\n",
       " ',',\n",
       " 'making',\n",
       " 'it',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'choice',\n",
       " 'for',\n",
       " 'industrial',\n",
       " 'applications',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: In wordpunct_tokenize apostrophe has also got splitted but in word_tokenize is not splitted\n",
    "\n",
    "1. wordpunct_tokenize: It's---> \"It\", \" '\", \"s\"\n",
    "2. word_tokenize: It's---> \"It\", \"'s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tool',\n",
       " 'for',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'for',\n",
       " 'tasks',\n",
       " 'that',\n",
       " 'require',\n",
       " 'flexibility',\n",
       " 'and',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'functions.',\n",
       " 'It',\n",
       " \"'s\",\n",
       " 'more',\n",
       " 'suited',\n",
       " 'for',\n",
       " 'academic',\n",
       " 'and',\n",
       " 'research',\n",
       " 'purposes',\n",
       " 'where',\n",
       " 'detailed',\n",
       " 'customization',\n",
       " 'and',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'array',\n",
       " 'of',\n",
       " 'tools',\n",
       " 'are',\n",
       " 'necessary.',\n",
       " 'spaCy',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'for',\n",
       " 'performance',\n",
       " 'and',\n",
       " 'ease',\n",
       " 'of',\n",
       " 'use',\n",
       " '!',\n",
       " 'making',\n",
       " 'it',\n",
       " 'ideal',\n",
       " 'for',\n",
       " 'production',\n",
       " 'environments',\n",
       " 'where',\n",
       " 'speed',\n",
       " 'and',\n",
       " 'accuracy',\n",
       " 'are',\n",
       " 'critical.',\n",
       " 'It',\n",
       " \"'s\",\n",
       " 'highly',\n",
       " 'efficient',\n",
       " 'and',\n",
       " 'comes',\n",
       " 'with',\n",
       " 'excellent',\n",
       " 'pre-trained',\n",
       " 'models',\n",
       " ',',\n",
       " 'making',\n",
       " 'it',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'choice',\n",
       " 'for',\n",
       " 'industrial',\n",
       " 'applications',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "t=TreebankWordTokenizer()\n",
    "t.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: using TreebankWordTokenizer full stop will not be treated as a separate word it will be included in the previous word itself. But with respect to the last word full stop will be separated. for last full stop only it considering as a separate word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLTK', 'is', 'a', 'great', 'tool', 'for', 'learning', 'and', 'for', 'tasks', 'that', 'require', 'flexibility', 'and', 'a', 'wide', 'range', 'of', 'NLP', 'functions', '.', 'It', \"'s\", 'more', 'suited', 'for', 'academic', 'and', 'research', 'purposes', 'where', 'detailed', 'customization', 'and', 'a', 'wide', 'array', 'of', 'tools', 'are', 'necessary', '.', 'spaCy', 'is', 'designed', 'for', 'performance', 'and', 'ease', 'of', 'use', '!', 'making', 'it', 'ideal', 'for', 'production', 'environments', 'where', 'speed', 'and', 'accuracy', 'are', 'critical', '.', 'It', \"'s\", 'highly', 'efficient', 'and', 'comes', 'with', 'excellent', 'pre', '-', 'trained', 'models', ',', 'making', 'it', 'a', 'strong', 'choice', 'for', 'industrial', 'applications', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp=English()\n",
    "doc=nlp(corpus)\n",
    "tokens=[token.text for token in doc]\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
