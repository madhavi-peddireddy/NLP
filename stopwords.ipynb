{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\" We expect that many readers of this book have heard of deep learning as an exciting new technology, and are surprised to see a mention of “history” in a book about an emerging ﬁeld. In fact, deep learning dates back to the 1940s. Deep learning only appears to be new, because it was relatively unpopular for several years preceding its current popularity, and because it has gone through many diﬀerent names, and has only recently become called “deep learning.” The ﬁeld has been rebranded many times, reﬂecting the inﬂuence of diﬀerent researchers and diﬀerent perspectives.\n",
    "A comprehensive history of deep learning is beyond the scope of this textbook. However, some basic context is useful for understanding deep learning. Broadly speaking, there have been three waves of development of deep learning: deep learning known as cybernetics in the 1940s–1960s, deep learning known as connectionism in the 1980s–1990s, and the current resurgence under the name deep learning beginning in 2006. This is quantitatively illustrated in ﬁgure 1.7.\n",
    "Some of the earliest learning algorithms we recognize today were intended to be computational models of biological learning, i.e. models of how learning happens or could happen in the brain. As a result, one of the names that deep learning has gone by is artiﬁcial neural networks (ANNs). The corresponding perspective on deep learning models is that they are engineered systems inspired by the biological brain (whether the human brain or the brain of another animal). While the kinds of neural networks used for machine learning have sometimes been used to understand brain function (Hinton and Shallice, 1991), they are generally not designed to be realistic models of biological function. The neural perspective on deep learning is motivated by two main ideas. One idea is that the brain provides a proof by example that intelligent behavior is possible, and a conceptually straightforward path to building intelligence is to reverse engineer the computational principles behind the brain and duplicate its functionality. Another perspective is that it would be deeply interesting to understand the brain and the principles that underlie human intelligence, so machine learning models that shed light on these basic scientiﬁc questions are useful apart from their ability to solve engineering applications. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Intel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "sentences=nltk.sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' We expect that many readers of this book have heard of deep learning as an exciting new technology, and are surprised to see a mention of “history” in a book about an emerging ﬁeld.',\n",
       " 'In fact, deep learning dates back to the 1940s.',\n",
       " 'Deep learning only appears to be new, because it was relatively unpopular for several years preceding its current popularity, and because it has gone through many diﬀerent names, and has only recently become called “deep learning.” The ﬁeld has been rebranded many times, reﬂecting the inﬂuence of diﬀerent researchers and diﬀerent perspectives.',\n",
       " 'A comprehensive history of deep learning is beyond the scope of this textbook.',\n",
       " 'However, some basic context is useful for understanding deep learning.',\n",
       " 'Broadly speaking, there have been three waves of development of deep learning: deep learning\\xa0known\\xa0as cybernetics in\\xa0the\\xa01940s–1960s,\\xa0deep\\xa0learning\\xa0known as connectionism in the 1980s–1990s, and the current resurgence under the name deep learning beginning in 2006.',\n",
       " 'This is quantitatively illustrated in ﬁgure 1.7.',\n",
       " 'Some of the earliest learning algorithms we recognize today were intended to be computational models of biological learning, i.e.',\n",
       " 'models of how learning happens or could happen in the brain.',\n",
       " 'As a result, one of the names that deep learning has gone by is artiﬁcial neural networks (ANNs).',\n",
       " 'The corresponding perspective on deep learning models is that they are engineered systems inspired by the biological brain (whether the human brain or the brain of another animal).',\n",
       " 'While the kinds of neural networks used for machine learning have sometimes been used to understand brain function (Hinton and Shallice, 1991), they are generally not designed to be realistic models of biological function.',\n",
       " 'The neural perspective on deep learning is motivated by two main ideas.',\n",
       " 'One idea is that the brain provides a proof by example that intelligent behavior is possible, and a conceptually straightforward path to building intelligence is to reverse engineer the computational principles behind the brain and duplicate its functionality.',\n",
       " 'Another perspective is that it would be deeply interesting to understand the brain and the principles that underlie human intelligence, so machine learning models that shed light on these basic scientiﬁc questions are useful apart from their ability to solve engineering applications.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i]) \n",
    "    # if word not in stopwords then only you apply stemming\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english')) ]\n",
    "    #converting all the words into sentences\n",
    "    sentences[i]=' '.join(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we expect mani reader book heard deep learn excit new technolog , surpris see mention “ histori ” book emerg ﬁeld .',\n",
       " 'in fact , deep learn date back 1940 .',\n",
       " 'deep learn appear new , rel unpopular sever year preced current popular , gone mani diﬀer name , recent becom call “ deep learning. ” the ﬁeld rebrand mani time , reﬂect inﬂuenc diﬀer research diﬀer perspect .',\n",
       " 'a comprehens histori deep learn beyond scope textbook .',\n",
       " 'howev , basic context use understand deep learn .',\n",
       " 'broadli speak , three wave develop deep learn : deep learn known cybernet 1940s–1960 , deep learn known connection 1980s–1990 , current resurg name deep learn begin 2006 .',\n",
       " 'thi quantit illustr ﬁgure 1.7 .',\n",
       " 'some earliest learn algorithm recogn today intend comput model biolog learn , i.e .',\n",
       " 'model learn happen could happen brain .',\n",
       " 'as result , one name deep learn gone artiﬁci neural network ( ann ) .',\n",
       " 'the correspond perspect deep learn model engin system inspir biolog brain ( whether human brain brain anoth anim ) .',\n",
       " 'while kind neural network use machin learn sometim use understand brain function ( hinton shallic , 1991 ) , gener design realist model biolog function .',\n",
       " 'the neural perspect deep learn motiv two main idea .',\n",
       " 'one idea brain provid proof exampl intellig behavior possibl , conceptu straightforward path build intellig revers engin comput principl behind brain duplic function .',\n",
       " 'anoth perspect would deepli interest understand brain principl underli human intellig , machin learn model shed light basic scientiﬁc question use apart abil solv engin applic .']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i]) \n",
    "    # if word not in stopwords then only you apply stemming\n",
    "    words=[snowball.stem(word) for word in words if word not in set(stopwords.words('english')) ]\n",
    "    #converting all the words into sentences\n",
    "    sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we expect mani reader book heard deep learn excit new technolog , surpris see mention “ histori ” book emerg ﬁeld .',\n",
       " 'in fact , deep learn date back 1940s .',\n",
       " 'deep learn appear new , relat unpopular sever year preced current popular , gone mani diﬀer name , recent becom call “ deep learning. ” the ﬁeld rebrand mani time , reﬂect inﬂuenc diﬀer research diﬀer perspect .',\n",
       " 'a comprehens histori deep learn beyond scope textbook .',\n",
       " 'howev , basic context use understand deep learn .',\n",
       " 'broad speak , three wave develop deep learn : deep learn known cybernet 1940s–1960s , deep learn known connection 1980s–1990s , current resurg name deep learn begin 2006 .',\n",
       " 'this quantit illustr ﬁgure 1.7 .',\n",
       " 'some earliest learn algorithm recogn today intend comput model biolog learn , i.e .',\n",
       " 'model learn happen could happen brain .',\n",
       " 'as result , one name deep learn gone artiﬁci neural network ( ann ) .',\n",
       " 'the correspond perspect deep learn model engin system inspir biolog brain ( whether human brain brain anoth anim ) .',\n",
       " 'while kind neural network use machin learn sometim use understand brain function ( hinton shallic , 1991 ) , general design realist model biolog function .',\n",
       " 'the neural perspect deep learn motiv two main idea .',\n",
       " 'one idea brain provid proof exampl intellig behavior possibl , conceptu straightforward path build intellig revers engin comput principl behind brain duplic function .',\n",
       " 'anoth perspect would deepli interest understand brain principl underli human intellig , machin learn model shed light basic scientiﬁc question use apart abil solv engin applic .']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "Lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i]=sentences[i].lower()\n",
    "    words=nltk.word_tokenize(sentences[i]) \n",
    "    # if word not in stopwords then only you apply stemming\n",
    "    words=[Lemmatizer.lemmatize(word, pos='v') for word in words if word not in set(stopwords.words('english')) ]\n",
    "    #converting all the words into sentences\n",
    "    sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expect many readers book hear deep learn excite new technology , surprise see mention “ history ” book emerge ﬁeld .',\n",
       " 'fact , deep learn date back 1940s .',\n",
       " 'deep learn appear new , relatively unpopular several years precede current popularity , go many diﬀerent name , recently become call “ deep learning. ” ﬁeld rebranded many time , reﬂecting inﬂuence diﬀerent researchers diﬀerent perspectives .',\n",
       " 'comprehensive history deep learn beyond scope textbook .',\n",
       " 'however , basic context useful understand deep learn .',\n",
       " 'broadly speak , three wave development deep learn : deep learn know cybernetics 1940s–1960s , deep learn know connectionism 1980s–1990s , current resurgence name deep learn begin 2006 .',\n",
       " 'quantitatively illustrate ﬁgure 1.7 .',\n",
       " 'earliest learn algorithms recognize today intend computational model biological learn , i.e .',\n",
       " 'model learn happen could happen brain .',\n",
       " 'result , one name deep learn go artiﬁcial neural network ( anns ) .',\n",
       " 'correspond perspective deep learn model engineer systems inspire biological brain ( whether human brain brain another animal ) .',\n",
       " 'kinds neural network use machine learn sometimes use understand brain function ( hinton shallice , 1991 ) , generally design realistic model biological function .',\n",
       " 'neural perspective deep learn motivate two main ideas .',\n",
       " 'one idea brain provide proof example intelligent behavior possible , conceptually straightforward path build intelligence reverse engineer computational principles behind brain duplicate functionality .',\n",
       " 'another perspective would deeply interest understand brain principles underlie human intelligence , machine learn model shed light basic scientiﬁc question useful apart ability solve engineer applications .']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
